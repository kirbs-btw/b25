{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B25 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tokenized_data/playlist_names/dataset_train.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_dataset, vector_size=256, window=20, min_count=1, workers=10)\n",
    "word2vec_model.save(\"../models/b25-sn-v256/b25-sn-v256-e.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation\n",
    "CBOW and other learning algorithms focus more on the words near the target word. That makes sense for Natural Language Understanding, but I'm working with playlists, where the weighting of context words is irrelevant.\n",
    "\n",
    "There are some ways to minimize this, but I might need to implement my own training algorithm to eliminate these types of caveats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(\n",
    "    sentences=train_dataset, \n",
    "    vector_size=256, \n",
    "    window=20,\n",
    "    min_count=1, \n",
    "    workers=10,\n",
    "    sg=1,            \n",
    "    ns_exponent=0.0\n",
    ")\n",
    "\"\"\"\n",
    "sg=1 means it is using the Skip Gram Algorithm wich is a bit less biased towards\n",
    "closer context words\n",
    "Also ns_exponent=0.0 means equal weighting for negative sampling\n",
    "\"\"\"\n",
    "\n",
    "word2vec_model.save(\"../models/b25-sn-v256/b25-sn-v256-e.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
