{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B25 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tokenized_data/playlist_names/dataset_train.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_dataset, workers=10, vector_size=50, window=5, min_count=1, sg=0)\n",
    "word2vec_model.save(\"../models/b25-sn-v50/b25-sn-v50.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_dataset, workers=10, vector_size=256, window=5, min_count=1, sg=0)\n",
    "word2vec_model.save(\"../models/b25-sn-v256/b25-sn-v256-a.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_dataset, workers=10, vector_size=256, window=10, min_count=1, sg=0)\n",
    "word2vec_model.save(\"../models/b25-sn-v256/b25-sn-v256-b.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_dataset, workers=10, vector_size=256, window=20, min_count=1, sg=0)\n",
    "word2vec_model.save(\"../models/b25-sn-v256/b25-sn-v256-c.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_dataset, workers=10, vector_size=256, window=20, min_count=1, sg=1, ns_exponent=0.0)\n",
    "word2vec_model.save(\"../models/b25-sn-v256/b25-sn-v256-d.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_dataset, workers=10, vector_size=512, window=100, min_count=1, sg=0)\n",
    "word2vec_model.save(\"../models/b25-sn-v512/b25-sn-v512-a.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_dataset, workers=10, vector_size=512, window=100, min_count=1, sg=1, ns_exponent=0.0)\n",
    "word2vec_model.save(\"../models/b25-sn-v512/b25-sn-v512-b.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoche: 0\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 1\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 2\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 3\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 4\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lipka\\HARD_DRIVE\\Projekte\\Projekte\\Project 146\\b25-model\\song2vec\\song2vec\\submodule\\song2vec.py:66: RuntimeWarning: invalid value encountered in subtract\n",
      "  dist_vector = np.subtract(current_vector, context_vector)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 6\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 7\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 8\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 9\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 10\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 11\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 12\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 13\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n",
      "Epoche: 14\n",
      "epochwrapup\n",
      "mainskips 0\n",
      "sub skips 0\n",
      "total sub 71149856\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_dir = os.path.abspath(\"../song2vec\")  \n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import song2vec.submodule\n",
    "\n",
    "a = song2vec.submodule.Song2Vec(train_dataset[0:500], vector_size=512, epochs=10, learning_rate=0.015)\n",
    "\n",
    "\n",
    "a.save(\"../models/b25-sn-v512/b25-sn-v512-f.pkl\")\n",
    "\n",
    "# need some working with nan values in the dataset... or with nan values in the keys...\n",
    "\n",
    "# 7.803 for 100\n",
    "# 5670.13 * 7.803 that would be 1.4 years of training...\n",
    "\n",
    "# generally it's an issues with floats in there\n",
    "# need to cast every element of the list to string and also somehow ignore the nan values\n",
    "# some data cleaning is needed to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param\n",
    "\n",
    "#### b25-sn-v50\n",
    "> vector_size=50, window=5, min_count=1, sg=0\n",
    "\n",
    "#### b25-sn-v256-a\n",
    "> vector_size=256, window=5, min_count=1, sg=0\n",
    "\n",
    "#### b25-sn-v256-b\n",
    "> vector_size=256, window=10, min_count=1, sg=0\n",
    "\n",
    "#### b25-sn-v256-c\n",
    "> vector_size=256, window=20, min_count=1, sg=0\n",
    "\n",
    "#### b25-sn-v256-d\n",
    "> vector_size=256, window=20, min_count=1, sg=1, ns_exponent=0.0\n",
    "\n",
    "#### b25-sn-v512-a\n",
    "> vector_size=512, window=100, min_count=1, sg=0\n",
    "\n",
    "#### b25-sn-v512-b\n",
    "> vector_size=512, window=100, min_count=1, sg=1, ns_exponent=0.0\n",
    "\n",
    "#### b25-sn-v512-c - CBOS\n",
    "> vector_size=512, epochs=5, learning_rate=0.01\n",
    "\n",
    "#### b25-sn-v512-d - CBOS\n",
    "> vector_size=512, epochs=5, learning_rate=0.015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation\n",
    "CBOW and other learning algorithms focus more on the words near the target word. That makes sense for Natural Language Understanding, but I'm working with playlists, where the weighting of context words is irrelevant.\n",
    "\n",
    "There are some ways to minimize this, but I might need to implement my own training algorithm to eliminate these types of caveats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(\n",
    "    sentences=train_dataset, \n",
    "    vector_size=256, \n",
    "    window=20,\n",
    "    min_count=1, \n",
    "    workers=10,\n",
    "    sg=1,            \n",
    "    ns_exponent=0.0\n",
    ")\n",
    "\"\"\"\n",
    "sg=1 means it is using the Skip Gram Algorithm wich is a bit less biased towards\n",
    "closer context words\n",
    "Also ns_exponent=0.0 means equal weighting for negative sampling\n",
    "\"\"\"\n",
    "\n",
    "word2vec_model.save(\"../models/b25-sn-v256/b25-sn-v256-e.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
